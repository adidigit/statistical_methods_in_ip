{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uXrAM0RgCgl8"
   },
   "source": [
    "# Statistical Methods in Image Processing EE-048954\n",
    "## Homework 2: Langevin Dynamics and Energy-Based Models\n",
    "### Due Date: <span style=\"color:red\">May 31, 2022</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Submission Guidelines\n",
    "\n",
    "* Submission only in **pairs** on the course website (Moodle).\n",
    "* Working environment:\n",
    "    * We encourage you to work in `Jupyter Notebook` online using <a href=\"https://colab.research.google.com/\">Google Colab</a> as it does not require any installation.\n",
    "* You should submit two **separated** files:\n",
    "    * A `.ipynb` file, with the name: `ee048954_hw2_id1_id2.ipynb` which contains your code implementations.\n",
    "    * A `.pdf` file, with the name: `ee048954_hw2_id1_id2.pdf` which is your report containing plots, answers, and discussions.\n",
    "    * **No handwritten submissions** and no other file-types (`.docx`, `.html`, ...) will be accepted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aXYdlXNS4c6V"
   },
   "source": [
    "### Mounting your drive for saving/loading stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VtmwdpfGMmjD",
    "outputId": "bd97d2b8-531f-486b-c5f7-8ccab95baec3"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kXPsd-7TgsCN"
   },
   "source": [
    "### Importing relevant libraries for Part I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XFz780qygx3J"
   },
   "outputs": [],
   "source": [
    "## Standard libraries\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "\n",
    "## Scikit-learn built-in dataset generator\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "## Progress bar\n",
    "import tqdm\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6BxH6tQygjiN"
   },
   "source": [
    "## Part I: Toy 2D Dataset (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework we will look into stochastic sampling techniques that could be used to sample from energy-based models of images. But, to kick things off, we will first start with the simple toy 2D dataset comprised of 5 rotated and equally-spaced Gaussian Mixture distribution we are familiar with from HW1 with slight adjustments: \n",
    "\n",
    "<center width=\"100%\"><img src=\"https://drive.google.com/uc?id=1DUVGzms8W_u7HrVyFb1QSxeszY9cs8Nr\" width=\"800px\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More formally, the probability density distribution considered is given by:\n",
    "\n",
    "  $$p(x;\\sigma,\\{\\mu_i\\}) = \\frac{1}{M} \\sum_{m=1}^{M} \\frac{1}{2\\pi\\sigma^2} \\exp\\left\\{-\\frac{1}{2\\sigma^2}||x-\\mu_i||^2\\right\\} ,$$\n",
    "   with $M = 5$, $\\sigma^2 = 0.1$, \n",
    "   \n",
    "   and $\\{\\mu_m\\} = 0.7 \\cdot \\{(1,0)^T , (\\cos(\\frac{2\\pi}{5}),\\sin(\\frac{2\\pi}{5}))^T , (\\cos(\\frac{4\\pi}{5}),\\sin(\\frac{4\\pi}{5}))^T , (\\cos(\\frac{6\\pi}{5}),\\sin(\\frac{6\\pi}{5}))^T , (\\cos(\\frac{8\\pi}{5}),\\sin(\\frac{8\\pi}{5}))^T\\}$.\n",
    "  \n",
    "<img src=\"https://img.icons8.com/offices/80/000000/making-notes.png\" style=\"height:30px;display:inline\\\">**<span style=\"color:red\">Task 1</span>**. Write down the analytical gradient of $\\log p(x)$ with respect to $x$. i.e. $\\nabla_x \\log p(x)$.\n",
    "\n",
    "While this distribution can be sampeld trivially using standard techniques, here we will sample from it using Langevin Dynamics. \n",
    "\n",
    "<img src=\"https://img.icons8.com/offices/80/000000/making-notes.png\" style=\"height:30px;display:inline\\\">**<span style=\"color:red\">Task 2</span>**. Implement Langevin Dynamics for sampling from $p(x)$:\n",
    "* Initialize 1000 random 2D points $x$ i.i.d distributed according to $U[-3.0,3.0]$.\n",
    "\n",
    "* Update the points according to the Langevin Dynamics update step:\n",
    "$$x^{k+1} = x^k + \\varepsilon \\nabla \\log p(x^k) + \\sqrt{2\\varepsilon}N^k.$$\n",
    "Use $\\sqrt{2\\varepsilon}=\\frac{10}{256}$ and $N \\sim \\mathcal{N}(0,I)$.\n",
    "\n",
    "* Repeat the previous step for $K=5000$ iterations.\n",
    "\n",
    "<img src=\"https://img.icons8.com/offices/80/000000/making-notes.png\" style=\"height:30px;display:inline\\\">**<span style=\"color:red\">Task 3</span>**. Draw $N = 1000$ samples ${x_i}$ from $p(x)$ using the provided code lines below and compare them visually to the samples drawn using Langevin Dynamics. Present both sample types and discuss the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples, seed, = 1000 , 0\n",
    "np.random.seed(seed)\n",
    "angles = np.linspace(0, 2 * np.pi, 5, endpoint=False)\n",
    "centers = np.stack([0.7 * np.array([np.cos(angle), np.sin(angle)]) for angle in angles])\n",
    "real_samples = make_blobs(num_samples, centers=centers, cluster_std=np.sqrt(.1), random_state=seed, shuffle=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://img.icons8.com/offices/80/000000/making-notes.png\" style=\"height:30px;display:inline\\\">**<span style=\"color:red\">Task 4</span>**. Repeat Tasks 2 and 3, this time with $\\sqrt{2\\varepsilon}=\\left\\{\\frac{1}{256}, \\frac{200}{256}\\right\\}$. Compare the results to Task 3, and explain the effect of $\\varepsilon$ on the resulting samples. Tip: To have a clear visual examination of the phenomenon, plot the path a sampled point goes through throughout the dynamics for different values of $\\varepsilon$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kXPsd-7TgsCN"
   },
   "source": [
    "### Importing additional relevant libraries for Parts II-IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Useful for creating GIFs\n",
    "import imageio\n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# Function for setting the seed\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "set_seed(42)\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.determinstic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# device to be used for Parts II-IV is preferably a GPU\n",
    "# try to change the runtime type to GPU if you can in Google Colab\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Using device\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cDTnZBzDg_7i"
   },
   "source": [
    "## Part II: Langevin Dynamics (30 points) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WdTZwoJzCgmC"
   },
   "source": [
    "In the remainder of this exercise we will focus on sampling from an Energy Based Model (EBM) that was trained to fit the distribution $p(x)$ of the [MNIST digits dataset](http://yann.lecun.com/exdb/mnist/) (no need to download the dataset). The EBM is given in the form of a Convolutional Neural Network (CNN), and defined by\n",
    "$$ p_\\theta(x) = \\frac{1}{Z(\\theta)}e^{-E_\\theta(x)}.$$\n",
    "Specifically, the model gets an image $x$ and returns $E_\\theta(x)$, where $\\theta$ are the trained model parameters. We will use this model in order to sample new digits from the MNIST distribution. In order to do so, we will use MCMC with Langevin Dynamics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided class below `ResNet` implements the neural network approximating $E(x)$ with a parametric function $E_{\\theta}(x)$, and is based on the architecture from the paper [wide residual networks](https://arxiv.org/abs/1605.07146). Note that for our purposes in this exercise you **don't** need to understand this class thoroughly. You can treat this network as a black-box that accepts an image $x$ as input and returns $E_{\\theta}(x) \\approx E(x)$ as output, and can also provide us with the gradient of $E(x)$ with respect to its input using automatic differentiation, i.e. $\\nabla_x E(x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the next lines define the architecture of the model and its functionality in forward path \n",
    "# (e.g how it operates when inputting an image)\n",
    "class ResNet(torch.nn.Module):\n",
    "    def __init__(self, n_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        levels_params = [\n",
    "            {'n_channels': 16, 'n_blocks': 2, 'downsample': False},\n",
    "            {'n_channels': 32, 'n_blocks': 2, 'downsample': True},\n",
    "            {'n_channels': 64, 'n_blocks': 2, 'downsample': True},\n",
    "            {'n_channels': 64, 'n_blocks': 2, 'downsample': True},\n",
    "            ]\n",
    "\n",
    "        self._el = torch.nn.ModuleDict()\n",
    "\n",
    "        self._el['in_conv'] = torch.nn.Conv2d(n_channels, 16, kernel_size=3, padding=3)\n",
    "        n_channels = 16\n",
    "\n",
    "        levels = torch.nn.ModuleList()\n",
    "        for level_params in levels_params:\n",
    "            level = torch.nn.ModuleDict()\n",
    "            res_blocks = torch.nn.ModuleList()\n",
    "\n",
    "            ## The first residual block in the level\n",
    "            res_block = torch.nn.ModuleDict()\n",
    "            n_channels_out = level_params['n_channels']\n",
    "            if level_params['downsample']:\n",
    "                res_block['shortcut_conv'] = torch.nn.Conv2d(n_channels, n_channels_out, kernel_size=2, stride=2)\n",
    "            else:\n",
    "                res_block['shortcut_conv'] = torch.nn.Conv2d(n_channels, n_channels_out, kernel_size=1)\n",
    "            res_block['conv_1'] = torch.nn.Conv2d(n_channels, n_channels_out, kernel_size=3, padding=1)\n",
    "            n_channels = n_channels_out\n",
    "            if level_params['downsample']:\n",
    "                res_block['conv_2'] = torch.nn.Conv2d(n_channels, n_channels, kernel_size=4, stride=2, padding=1)\n",
    "            else:\n",
    "                res_block['conv_2'] = torch.nn.Conv2d(n_channels, n_channels, kernel_size=3, stride=1, padding=1)\n",
    "            res_blocks.append(res_block)\n",
    "\n",
    "            ## The rest of the residual blocks in the level\n",
    "            for _ in range(level_params['n_blocks'] - 1):\n",
    "                res_block = torch.nn.ModuleDict()\n",
    "                res_block['conv_1'] = torch.nn.Conv2d(n_channels, n_channels, kernel_size=3, padding=1)\n",
    "                res_block['conv_2'] = torch.nn.Conv2d(n_channels, n_channels, kernel_size=3, padding=1)\n",
    "                res_blocks.append(res_block)\n",
    "            level['res_blocks'] = res_blocks\n",
    "            levels.append(level)\n",
    "        self._el['levels'] = levels\n",
    "\n",
    "        self._el['out_fc'] = torch.nn.Linear(n_channels, 1, bias=False)\n",
    "\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, torch.nn.Conv2d):\n",
    "                torch.nn.init.xavier_uniform_(module.weight, gain=2 ** 0.5)\n",
    "                if module.bias is not None:\n",
    "                    module.bias.data.zero_()\n",
    "\n",
    "    # functionality when inputting image x to the model:\n",
    "    def forward(self, x):\n",
    "        x = self._el['in_conv'](x)\n",
    "\n",
    "        for level in self._el['levels']:\n",
    "            for res_block in level['res_blocks']:\n",
    "                shortcut = x\n",
    "                x = torch.nn.functional.leaky_relu(x, 0.2)\n",
    "                x = res_block['conv_1'](x)\n",
    "                x = torch.nn.functional.leaky_relu(x, 0.2)\n",
    "                x = res_block['conv_2'](x)\n",
    "                if 'shortcut_conv' in res_block:\n",
    "                    shortcut = res_block['shortcut_conv'](shortcut)\n",
    "                x = x + shortcut\n",
    "\n",
    "        x = torch.nn.functional.leaky_relu(x, 0.2)\n",
    "        x = x.view(x.shape[0], x.shape[1], -1).sum(dim=2)\n",
    "        x = self._el['out_fc'](x)\n",
    "\n",
    "        return x[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For your convinience, we provide pre-trained model weights $\\theta^{\\star}$ on the MNIST dataset, Courtesy of Mr. Omer Yair. To instantiate the model and load the pretrained weights $\\theta^{\\star}$ from the attached file `checkpoint.pt`, you can use the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the class above for images with 1 channel and load it to the device (CPU/GPU)\n",
    "ebm = ResNet(n_channels=1).to(device)\n",
    "\n",
    "# transfer the model to evaluation mode (as we don't want to train it, just to use it)\n",
    "ebm.eval()\n",
    "\n",
    "# load the trained model weights/parameters from the checkpoint file\n",
    "checkpoint_path = 'checkpoint.pt'\n",
    "ebm.load_state_dict(torch.load(checkpoint_path, map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading the trained weights $\\theta^{\\star}$, we can feed the model with images $x$ and get their approximated energy $E_{\\theta^{\\star}}(x)$ by a simple forward pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of images to generate\n",
    "n_imgs = 30\n",
    "\n",
    "# randomly initialized 28x28x1 images with i.i.d pixels ~U[0,1]\n",
    "imgs = torch.rand((n_imgs, 1, 28, 28), device=device)\n",
    "\n",
    "# set the images to have a gradient graph so we could calculate the gradient of the model\n",
    "imgs.requires_grad_(True)\n",
    "\n",
    "# run the model: input the images x, getting as output their estimated energy E(x)\n",
    "energy = ebm(imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the gradient of the model output $E(x)$ with respect to the input images $x$, we can use automatic differentiation because we previously set the `requires_grad_` property of the input images to `True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the gradient of the model: grad(E(x)) with respect to x.\n",
    "grad = torch.autograd.grad(energy.sum(), imgs)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://img.icons8.com/offices/80/000000/making-notes.png\" style=\"height:30px;display:inline\\\">**<span style=\"color:red\">Task 5</span>**. Run Langevin Dynamics for the provided EBM:\n",
    "* Initialize 30 random images of size $28\\times28$ distributed i.i.d according to $U[0,1]$.\n",
    "\n",
    "* Update the images according to the Langevin Dynamics update step:\n",
    "$$x^{k+1} = x^k + \\varepsilon \\nabla \\log p(x^k) + \\sqrt{2\\varepsilon}N^k.$$\n",
    "Use $\\sqrt{2\\varepsilon}=\\frac{2}{256}$ and $N \\sim \\mathcal{N}(0,I)$. Note that although we do not have an explicit expression for $p(x)$, but only for $E(x)$, we are still able to perform the update step, how? For calculating the gradient you can use automatic differentiation as described above.\n",
    "\n",
    "* Repeat the previous step for $K=2000$ iterations. Present the final samples and discuss the results.\n",
    "\n",
    "<img src=\"https://img.icons8.com/offices/80/000000/making-notes.png\" style=\"height:30px;display:inline\\\">**<span style=\"color:red\">Task 6</span>**. Repeat the previous task for $K=2000$ iterations, this time with $\\sqrt{2\\varepsilon}=\\frac{3}{256}$. Present the final samples and discuss the results comparing to the previous section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cDTnZBzDg_7i"
   },
   "source": [
    "## Part III: MALA (30 points) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now expand Part II into the Metropolis-Adjusted Langevin Algorithm (MALA):\n",
    "\n",
    "* Use the same initialization scheme as in Langevin Dynamics\n",
    "* use the same update step as before\n",
    "$$x^{k+1} = x^k + \\varepsilon \\nabla \\log p(x^k) + \\sqrt{2\\varepsilon}N^k,$$\n",
    "    with $\\sqrt{2\\varepsilon}=\\frac{2}{256}$ and $N \\sim \\mathcal{N}(0,I)$.\n",
    "* **Acceptance step**: accept the sample $x^{k+1}$ according to the acceptance rule:\n",
    "    * If $x^{k+1}$ is more probable than $x^k$ then accept $x^{k+1}$\n",
    "    * else, replace $x^{k+1}$ with $x^k$ with probability $\\alpha$, where\n",
    "    $$\\alpha \\triangleq \\frac{p(x^{k + 1}) q(x^k \\mid x^{k+1})}{p(x^k) q(x^{k+1}\\mid x^k)}$$\n",
    "    and\n",
    "    $$q(x'\\mid x) \\propto \\exp \\left( - \\frac{1}{4 \\varepsilon} \\| x' - x - \\varepsilon \\nabla \\log p(x) \\|_2^2 \\right).$$\n",
    "\n",
    "<img src=\"https://img.icons8.com/offices/80/000000/making-notes.png\" style=\"height:30px;display:inline\\\">**<span style=\"color:red\">Task 7</span>**. In the acceptance step of the MALA algorithm we can use $E(x)$ without explicitly knowing $p(x)$. Why?\n",
    "\n",
    "<img src=\"https://img.icons8.com/offices/80/000000/making-notes.png\" style=\"height:30px;display:inline\\\">**<span style=\"color:red\">Task 8</span>**. Apply the MALA algorithm for $K=2000$ iterations. Present the final samples and discuss the results. \n",
    "\n",
    "<img src=\"https://img.icons8.com/offices/80/000000/making-notes.png\" style=\"height:30px;display:inline\\\">**<span style=\"color:red\">Task 9</span>**. Apply the MALA algorithm for $K=2000$ iterations, with $\\sqrt{2\\varepsilon}=\\frac{3}{256}$. Present the final samples and discuss the results.\n",
    "\n",
    "<img src=\"https://img.icons8.com/offices/80/000000/making-notes.png\" style=\"height:30px;display:inline\\\">**<span style=\"color:red\">Task 10</span>**. Apply the MALA algorithm for $K=20,000$ iterations (it might take a few minutes), with $\\sqrt{2\\varepsilon}=\\frac{3}{256}$. **Instead of random initialization**, run Langevin dynamics as in Part II with $\\sqrt{2\\varepsilon}=\\frac{2}{256}$ for $K=500$ iterations and use these images as your initialization for the MALA algorithm. Present the final samples and examples for samples in intermediate iterations. Discuss the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cDTnZBzDg_7i"
   },
   "source": [
    "## Part IV: Perceptual and MMSE Denoising (30 points) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a noisy image $y = x + n$, where $x$ is a clean image and $n \\sim \\mathcal{N}(0, \\sigma^2I)$, we would like to estimate $x$ using Langevin Dynamics and the EBM model trained to estimate $p(x)$. We will perform denoising by drawing samples from $p(x|y)$.\n",
    "\n",
    "<img src=\"https://img.icons8.com/offices/80/000000/making-notes.png\" style=\"height:30px;display:inline\\\">**<span style=\"color:red\">Task 11</span>**. Write an explicit expression for $\\nabla_x\\log p(x|y)$ in terms of $p_x(x)$ and $p_n(n)$.\n",
    "\n",
    "<img src=\"https://img.icons8.com/offices/80/000000/making-notes.png\" style=\"height:30px;display:inline\\\">**<span style=\"color:red\">Task 12</span>**. How should the update step in Langevin Dynamics (Part II) be changed in order to draw samples from $p(x|y)$ instead of $p(x)$? We call such samples *perceptual* denoising results.\n",
    "\n",
    "<img src=\"https://img.icons8.com/offices/80/000000/making-notes.png\" style=\"height:30px;display:inline\\\">**<span style=\"color:red\">Task 13</span>**. The attachment of this exercise includes 30 noisy digits with $\\sigma=\\left\\{\\frac{50}{256},\\frac{100}{256}\\right\\}$ (you can load the images using the command `torch.load()`). Perform perceptual denoising with Langevin Dynamics with the parameters $K=2000$ and $\\sqrt{2\\varepsilon}=\\frac{2}{256}$. Present and discuss the results.\n",
    "\n",
    "<img src=\"https://img.icons8.com/offices/80/000000/making-notes.png\" style=\"height:30px;display:inline\\\">**<span style=\"color:red\">Task 14</span>**. Minimum MSE denoising can be obtained by averaging over the perceptual denoising results, since the conditional expectation $E[x|y]$ can be approximated by averaging over samples from $p(x|y)$ (namely, $E[x|y] \\approx \\frac{1}{N}\\sum_{n=1}^N x_n$, where $\\{x_n\\}$ are samples from $p(x|y)$). Present the MMSE results averages over 10 perceptual samples. Why do you think the task of *perceptual denoising* is called that way?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW1_Spring2022_Solved_Final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
